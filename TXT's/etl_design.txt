# ETL DESIGN DOCUMENT
## Healthcare Analytics: OLTP to Star Schema

---

## 1. ARCHITECTURE

### 1.1 Pipeline Flow
```
OLTP (Normalized) 
  → EXTRACT: Pull source data
  → TRANSFORM: Clean, enrich, aggregate  
  → LOAD: Insert into star schema
  → VALIDATE: Data quality checks
  → LOG: Record execution
```

### 1.2 Execution
- **Schedule:** Daily at 2:00 AM
- **Mode:** Full refresh (truncate & reload)
- **Duration:** ~3 minutes for 500K encounters
- **Throughput:** 174K encounters/min

### 1.3 File Structure
```
SQL_scripts/
├── star_schema.sql          # DDL
├── etl_logging_setup.sql    # Logging infrastructure
├── etl_pipeline.sql         # Main ETL logic
├── clean_star_schema.sql    # Truncate tables
```

---

## 2. LOGGING INFRASTRUCTURE

### 2.1 Tables

**etl_batch_control** - Batch execution tracking
- `batch_id`: YYYYMMDD_HHMMSS_XXX
- `status`: RUNNING | COMPLETED | COMPLETED_WITH_WARNINGS | FAILED
- `total_rows_processed`, `total_errors`
- `last_successful_encounter_id`: For restart capability

**etl_log** - Step-by-step execution log
- `log_level`: INFO | WARNING | ERROR
- `step_name`, `message`, `rows_affected`, `execution_time_seconds`

**etl_error_records** - Failed record details
- `source_table`, `source_id`, `error_type`, `error_message`
- `field_name`, `field_value`, `resolved`

### 2.2 Procedures
```sql
CALL start_etl_batch(@batch_id, 'FULL_REFRESH');
CALL log_etl_event(@batch_id, 'INFO', 'step', 'message', rows, seconds);
CALL log_etl_error(@batch_id, 'table', id, 'type', 'message', 'field', 'value');
CALL complete_etl_batch(@batch_id, 'COMPLETED', 'notes');
CALL get_batch_summary(@batch_id);
```

---

## 3. DIMENSION LOADS

### 3.1 Load Order
```
1. dim_date (one-time)
2. dim_specialty, dim_department, dim_encounter_type, dim_diagnosis, dim_procedure
3. dim_patient (batched: 20K/batch)
4. dim_provider (depends on dim_specialty)
```

### 3.2 dim_date (One-Time)
```
FOR each date FROM '2020-01-01' TO '2030-12-31':
  date_key = YYYYMMDD integer
  year, quarter, month, day_of_week
  quarter_name = 'Q2 2024'
  month_year = 'May 2024'
  is_weekend = (day_of_week IN (1,7))
  fiscal_year = IF month >= 7 THEN year ELSE year-1
  fiscal_quarter = calculated based on fiscal_year
  INSERT INTO dim_date
```
**Result:** 4,018 dates

### 3.3 dim_patient (Batched)
```
FOR batch IN (1-20K, 20K-40K, 40K-60K, 60K-80K, 80K-100K):
  
  # Log invalid records
  LOG patients WHERE date_of_birth IS NULL OR > CURDATE()
  
  # Load valid patients
  INSERT INTO dim_patient
    SELECT patient_id, mrn, first_name, last_name,
           CONCAT(first_name, ' ', last_name) AS full_name,
           date_of_birth, gender,
           CASE WHEN age < 18 THEN '0-17'
                WHEN age < 35 THEN '18-34'
                WHEN age < 50 THEN '35-49'
                WHEN age < 65 THEN '50-64'
                ELSE '65+' END AS age_group
    FROM patients
    WHERE date_of_birth IS NOT NULL AND date_of_birth <= CURDATE()
    AND patient_id BETWEEN batch_start AND batch_end
```
**Result:** 100K patients, 0 errors

### 3.4 dim_provider (Denormalized)
```
# Log providers with missing specialty
LOG providers WHERE specialty_id NOT IN dim_specialty

# Load with denormalized specialty
INSERT INTO dim_provider
  SELECT p.provider_id, p.first_name, p.last_name,
         CONCAT('Dr. ', p.first_name, ' ', p.last_name) AS full_name,
         p.credential, p.specialty_id,
         s.specialty_name,    # DENORMALIZED
         s.specialty_code     # DENORMALIZED
  FROM providers p
  INNER JOIN specialties s ON p.specialty_id = s.specialty_id
```
**Result:** 500 providers, 0 errors

---

## 4. FACT TABLE LOAD

### 4.1 Pre-Load: Create Lookup Tables
**Purpose:** Avoid 500K subqueries (hours → minutes)

```
CREATE TEMPORARY TABLE temp_patient_lookup AS
  SELECT patient_id, patient_key FROM dim_patient;

CREATE TEMPORARY TABLE temp_provider_lookup AS
  SELECT p.provider_id, dp.provider_key, ds.specialty_key
  FROM providers p
  JOIN dim_provider dp ON p.provider_id = dp.provider_id
  JOIN dim_specialty ds ON p.specialty_id = ds.specialty_id;

CREATE TEMPORARY TABLE temp_department_lookup AS
  SELECT department_id, department_key FROM dim_department;

CREATE TEMPORARY TABLE temp_encounter_type_lookup AS
  SELECT encounter_type_name, encounter_type_key FROM dim_encounter_type;

# Pre-aggregate counts
CREATE TEMPORARY TABLE temp_diagnosis_counts AS
  SELECT encounter_id, COUNT(*) AS diagnosis_count
  FROM encounter_diagnoses GROUP BY encounter_id;

CREATE TEMPORARY TABLE temp_procedure_counts AS
  SELECT encounter_id, COUNT(*) AS procedure_count
  FROM encounter_procedures GROUP BY encounter_id;

# Pre-aggregate revenue
CREATE TEMPORARY TABLE temp_billing_totals AS
  SELECT encounter_id,
         SUM(claim_amount) AS total_claim_amount,
         SUM(allowed_amount) AS total_allowed_amount
  FROM billing GROUP BY encounter_id;
```

### 4.2 Pre-Load: Validate Dimension Keys
```
LOG encounters WHERE patient_id NOT IN temp_patient_lookup AS 'MISSING_PATIENT_KEY'
LOG encounters WHERE provider_id NOT IN temp_provider_lookup AS 'MISSING_PROVIDER_KEY'
LOG encounters WHERE department_id NOT IN temp_department_lookup AS 'MISSING_DEPARTMENT_KEY'
LOG encounters WHERE encounter_type NOT IN temp_encounter_type_lookup AS 'MISSING_ENCOUNTER_TYPE'
```
**Result:** 0 validation errors

### 4.3 Load Fact Table (Batched: 100K/batch)
```
FOR batch IN (1-100K, 100K-200K, 200K-300K, 300K-400K, 400K-500K):
  
  INSERT INTO fact_encounters
    SELECT e.encounter_id,
           CAST(DATE_FORMAT(e.encounter_date, '%Y%m%d') AS UNSIGNED) AS date_key,
           tp.patient_key,
           tpr.provider_key,
           tpr.specialty_key,      # From temp_provider_lookup
           td.department_key,
           te.encounter_type_key,
           e.encounter_date,
           e.discharge_date,
           COALESCE(tdc.diagnosis_count, 0),     # PRE-AGGREGATED
           COALESCE(tpc.procedure_count, 0),     # PRE-AGGREGATED
           COALESCE(tb.total_claim_amount, 0),   # PRE-AGGREGATED
           COALESCE(tb.total_allowed_amount, 0), # PRE-AGGREGATED
           CASE WHEN e.encounter_type = 'Inpatient' AND e.discharge_date IS NOT NULL
                THEN DATEDIFF(e.discharge_date, e.encounter_date)
                ELSE NULL END AS length_of_stay_days
    FROM encounters e
    INNER JOIN temp_patient_lookup tp ON e.patient_id = tp.patient_id
    INNER JOIN temp_provider_lookup tpr ON e.provider_id = tpr.provider_id
    INNER JOIN temp_department_lookup td ON e.department_id = td.department_id
    INNER JOIN temp_encounter_type_lookup te ON e.encounter_type = te.encounter_type_name
    LEFT JOIN temp_diagnosis_counts tdc ON e.encounter_id = tdc.encounter_id
    LEFT JOIN temp_procedure_counts tpc ON e.encounter_id = tpc.encounter_id
    LEFT JOIN temp_billing_totals tb ON e.encounter_id = tb.encounter_id
    WHERE e.encounter_id BETWEEN batch_start AND batch_end
  
  UPDATE etl_batch_control SET last_successful_encounter_id = batch_end
  LOG batch completion
```
**Result:** 500K encounters, ~34 sec/batch, 0 errors

---

## 5. BRIDGE TABLE LOADS

### 5.1 bridge_encounter_diagnoses (Batched: 100K encounters/batch)
```
FOR batch IN (1-100K, 100K-200K, 200K-300K, 300K-400K, 400K-500K):
  
  # Log orphaned records
  LOG encounter_diagnoses WHERE encounter_id NOT IN fact_encounters AS 'ORPHAN_DIAGNOSIS'
  LOG encounter_diagnoses WHERE diagnosis_id NOT IN dim_diagnosis AS 'MISSING_DIAGNOSIS_KEY'
  
  # Load valid links
  INSERT INTO bridge_encounter_diagnoses
    SELECT tel.encounter_key,
           dd.diagnosis_key,
           ed.diagnosis_sequence
    FROM encounter_diagnoses ed
    INNER JOIN temp_encounter_lookup tel ON ed.encounter_id = tel.encounter_id
    INNER JOIN dim_diagnosis dd ON ed.diagnosis_id = dd.diagnosis_id
    WHERE ed.encounter_id BETWEEN batch_start AND batch_end
```
**Result:** 999,570 links, 0 orphans

### 5.2 bridge_encounter_procedures (Batched: 100K encounters/batch)
```
FOR batch IN (1-100K, 100K-200K, 200K-300K, 300K-400K, 400K-500K):
  
  # Log orphaned records
  LOG encounter_procedures WHERE encounter_id NOT IN fact_encounters AS 'ORPHAN_PROCEDURE'
  LOG encounter_procedures WHERE procedure_id NOT IN dim_procedure AS 'MISSING_PROCEDURE_KEY'
  
  # Load valid links with sequence
  INSERT INTO bridge_encounter_procedures
    SELECT tel.encounter_key,
           dp.procedure_key,
           ep.procedure_date,
           ROW_NUMBER() OVER (PARTITION BY tel.encounter_key 
                             ORDER BY ep.procedure_date, ep.encounter_procedure_id) AS sequence
    FROM encounter_procedures ep
    INNER JOIN temp_encounter_lookup tel ON ep.encounter_id = tel.encounter_id
    INNER JOIN dim_procedure dp ON ep.procedure_id = dp.procedure_id
    WHERE ep.encounter_id BETWEEN batch_start AND batch_end
```
**Result:** 1,500,221 links, 0 orphans

---

## 6. DATA QUALITY VALIDATION

```
CHECK 1: Encounter count
  OLTP: COUNT(*) FROM encounters
  Star: COUNT(*) FROM fact_encounters
  Status: MATCH (500,000 = 500,000)

CHECK 2: Patient count
  OLTP: COUNT(*) FROM patients
  Star: COUNT(*) FROM dim_patient
  Status: MATCH (100,000 = 100,000)

CHECK 3: Provider count
  OLTP: COUNT(*) FROM providers
  Star: COUNT(*) FROM dim_provider
  Status: MATCH (500 = 500)

CHECK 4: Diagnosis links
  OLTP: COUNT(*) FROM encounter_diagnoses
  Star: COUNT(*) FROM bridge_encounter_diagnoses
  Status: MATCH (999,570 = 999,570)

CHECK 5: Procedure links
  OLTP: COUNT(*) FROM encounter_procedures
  Star: COUNT(*) FROM bridge_encounter_procedures
  Status: MATCH (1,500,221 = 1,500,221)

CHECK 6: Revenue totals
  OLTP: SUM(allowed_amount) FROM billing
  Star: SUM(total_allowed_amount) FROM fact_encounters
  Status: MATCH ($3,575,482,020.31 = $3,575,482,020.31)

CHECK 7: NULL foreign keys
  Star: COUNT(*) FROM fact_encounters WHERE any FK IS NULL
  Status: PASS (0 NULL FKs)

CHECK 8: Orphaned bridge records
  Star: COUNT(*) FROM bridge tables WHERE encounter_key NOT IN fact_encounters
  Status: PASS (0 orphans)

CHECK 9: Sample diagnosis count
  Random encounter: Compare OLTP vs Star diagnosis_count
  Status: MATCH
```

---

## 7. ERROR HANDLING

### 7.1 Error Types
| Error Type | Description | Action |
|------------|-------------|--------|
| INVALID_DOB | NULL/future date_of_birth | Skip, log |
| MISSING_SPECIALTY | Invalid specialty_id | Skip, log |
| MISSING_PATIENT_KEY | Unknown patient | Skip, log |
| MISSING_PROVIDER_KEY | Unknown provider | Skip, log |
| MISSING_DEPARTMENT_KEY | Unknown department | Skip, log |
| MISSING_ENCOUNTER_TYPE | Unknown encounter type | Skip, log |
| ORPHAN_DIAGNOSIS | Diagnosis without encounter | Skip, log |
| ORPHAN_PROCEDURE | Procedure without encounter | Skip, log |
| MISSING_DIAGNOSIS_KEY | Unknown diagnosis | Skip, log |
| MISSING_PROCEDURE_KEY | Unknown procedure | Skip, log |

### 7.2 Error Handler Pattern
```sql
DECLARE EXIT HANDLER FOR SQLEXCEPTION
BEGIN
  GET DIAGNOSTICS CONDITION 1 v_error = MESSAGE_TEXT
  CALL log_etl_event(@batch_id, 'ERROR', 'step', v_error, 0, elapsed)
  ROLLBACK
  RESIGNAL
END
```

### 7.3 Batch Status Logic
```
status = CASE
  WHEN COUNT(ERROR logs) > 0 THEN 'FAILED'
  WHEN COUNT(error_records) > 0 THEN 'COMPLETED_WITH_WARNINGS'
  ELSE 'COMPLETED'
END
```

---

## 8. EXECUTION

### 8.1 First Time Setup
```sql
SOURCE Hospital_DDL.sql;
SOURCE generate_dataset.sql;
SOURCE star_schema.sql;
SOURCE etl_logging_setup.sql;
SOURCE etl_pipeline.sql;
CALL get_batch_summary(@batch_id);
```

### 8.2 Re-Run ETL
```sql
SOURCE clean_star_schema.sql;
SOURCE etl_pipeline.sql;
```

### 8.3 View Results
```sql
-- All batches
SELECT batch_id, status, 
       TIMESTAMPDIFF(MINUTE, start_timestamp, end_timestamp) AS minutes,
       total_rows_processed, total_errors
FROM etl_batch_control
ORDER BY start_timestamp DESC;

-- Specific batch
CALL get_batch_summary('20260121_130753_595');

-- Errors
SELECT * FROM etl_error_records WHERE resolved = FALSE;

-- Step details
SELECT log_timestamp, log_level, step_name, message, rows_affected, execution_time_seconds
FROM etl_log WHERE batch_id = @batch_id ORDER BY log_id;
```

---

## 9. PERFORMANCE

### 9.1 Actual Metrics
| Phase | Duration | Records |
|-------|----------|---------|
| Dimensions | 30s | 104,641 |
| Lookup Tables | 15s | 7 tables |
| Validation | 5s | 0 errors |
| Facts (5 batches) | 170s | 500,000 |
| Bridges (10 batches) | 30s | 2,499,791 |
| Data Quality | 18s | 9 checks |
| **TOTAL** | **2.87 min** | **3.1M records** |

### 9.2 Throughput
- Encounters: 174K/min
- Bridge records: 833K/min
- Overall: 1.08M records/min

### 9.3 Scalability
| Encounters | Est. Duration |
|------------|---------------|
| 500K | 2.87 min (actual) |
| 1M | ~6 min |
| 5M | ~30 min |
| 10M | ~60 min |

---

## 10. TROUBLESHOOTING

### 10.1 ETL Fails Mid-Batch
```sql
-- Find last step
SELECT * FROM etl_log 
WHERE batch_id = 'FAILED_BATCH' 
ORDER BY log_id DESC LIMIT 10;

-- Check errors
SELECT * FROM etl_log 
WHERE batch_id = 'FAILED_BATCH' AND log_level = 'ERROR';

-- Resolution
SOURCE clean_star_schema.sql;
SOURCE etl_pipeline.sql;
```

### 10.2 Data Mismatch
```sql
-- Compare counts
SELECT 'Encounters', 
       (SELECT COUNT(*) FROM encounters) AS oltp,
       (SELECT COUNT(*) FROM fact_encounters) AS star;

-- Find missing
SELECT e.encounter_id 
FROM encounters e
LEFT JOIN fact_encounters f ON e.encounter_id = f.encounter_id
WHERE f.encounter_key IS NULL;

-- Check why
SELECT * FROM etl_error_records WHERE source_id IN (...);
```

### 10.3 Performance Issues
```sql
-- Compare batch times
SELECT batch_id, TIMESTAMPDIFF(MINUTE, start_timestamp, end_timestamp) AS minutes
FROM etl_batch_control WHERE status = 'COMPLETED'
ORDER BY start_timestamp DESC LIMIT 10;

-- Slow steps
SELECT step_name, execution_time_seconds
FROM etl_log WHERE batch_id = 'SLOW_BATCH' AND execution_time_seconds > 60
ORDER BY execution_time_seconds DESC;
```

---

## 11. KEY DESIGN DECISIONS

1. **Full Refresh:** Simple, reliable, fast enough for daily loads
2. **Batching:** 20K for dimensions, 100K for facts - balance between speed and recoverability
3. **Temporary Lookup Tables:** Critical for performance (hours → minutes)
4. **Pre-Aggregation:** Counts and totals stored in fact table for query speed
5. **Denormalization:** Specialty name/code in dim_provider for query simplicity
6. **Comprehensive Logging:** Every step tracked for troubleshooting
7. **Error Isolation:** Bad records logged but don't stop ETL
8. **Restart Capability:** Track last successful encounter for future incremental loads

---
 
**Last Updated:** January 2026  
**Actual Performance:** 2.87 minutes | 0 errors | 100% data quality